{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723eb7a5",
      "metadata": {
        "id": "723eb7a5",
        "outputId": "279d72e1-f7b7-4bab-d7ff-c317e0d07bad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\pcoec\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b6b982",
      "metadata": {
        "id": "a8b6b982",
        "outputId": "91ecbc7f-0bb3-4124-f06e-8393dbbf17ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Sachin', 'is', 'considered', 'to', 'be', 'one', 'of', 'the', 'greatest', 'cricket', 'players', '.', 'Virat', 'is', 'the', 'captain', 'of', 'the', 'Indian', 'cricket', 'team']\n",
            "['Sachin is considered to be one of the greatest cricket players.', 'Virat is the captain of the Indian cricket team']\n"
          ]
        }
      ],
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "sent = \"Sachin is considered to be one of the greatest cricket players. Virat is the captain of the Indian cricket team\"\n",
        "print(word_tokenize(sent))\n",
        "print(sent_tokenize(sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308116bb",
      "metadata": {
        "id": "308116bb",
        "outputId": "e9696091-556d-42a5-c6c3-cc20ee37e489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\pcoec\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8411fe8",
      "metadata": {
        "id": "f8411fe8",
        "outputId": "28eecfbc-936a-4bee-f18f-7a7782cce706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the unclean version :  ['Sachin', 'is', 'considered', 'to', 'be', 'one', 'of', 'the', 'greatest', 'cricket', 'players', '.', 'Virat', 'is', 'the', 'captain', 'of', 'the', 'Indian', 'cricket', 'team']\n",
            "This is the cleaned version :  ['Sachin', 'considered', 'one', 'greatest', 'cricket', 'players', '.', 'Virat', 'captain', 'Indian', 'cricket', 'team']\n"
          ]
        }
      ],
      "source": [
        "token = word_tokenize(sent)\n",
        "cleaned_token = []\n",
        "for word in token:\n",
        " if word not in stop_words:\n",
        "    cleaned_token.append(word)\n",
        "\n",
        "print(\"This is the unclean version : \",token)\n",
        "print(\"This is the cleaned version : \",cleaned_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57060168",
      "metadata": {
        "id": "57060168"
      },
      "outputs": [],
      "source": [
        "words = [cleaned_token.lower() for cleaned_token in cleaned_token if cleaned_token.isalpha()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a59215e",
      "metadata": {
        "id": "4a59215e",
        "outputId": "3a6e654d-f30a-4457-f75c-a0cab40f3d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sachin', 'considered', 'one', 'greatest', 'cricket', 'players', 'virat', 'captain', 'indian', 'cricket', 'team']\n"
          ]
        }
      ],
      "source": [
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d682e8a3",
      "metadata": {
        "id": "d682e8a3",
        "outputId": "99b9bb82-15d4-4966-d8fb-2457ff535366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sachin', 'consid', 'one', 'greatest', 'cricket', 'player', 'virat', 'captain', 'indian', 'cricket', 'team']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "port_stemmer_output = [stemmer.stem(words) for words in words]\n",
        "print(port_stemmer_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c31f238",
      "metadata": {
        "id": "8c31f238",
        "outputId": "02e5881d-b1a1-4a65-b622-2cd752d21705"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\pcoec\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sachin', 'considered', 'one', 'greatest', 'cricket', 'player', 'virat', 'captain', 'indian', 'cricket', 'team']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizer_output = [lemmatizer.lemmatize(words) for words in words]\n",
        "print(lemmatizer_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6bede85",
      "metadata": {
        "id": "f6bede85",
        "outputId": "b3d312f2-e32e-49f1-80bd-884b826a105b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Sachin', 'NNP'), ('considered', 'VBD'), ('one', 'CD'), ('greatest', 'JJS'), ('cricket', 'NN'), ('players', 'NNS'), ('.', '.'), ('Virat', 'NNP'), ('captain', 'NN'), ('Indian', 'JJ'), ('cricket', 'NN'), ('team', 'NN')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\pcoec\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "token = word_tokenize(sent)\n",
        "cleaned_token = []\n",
        "for word in token:\n",
        " if word not in stop_words:\n",
        "    cleaned_token.append(word)\n",
        "tagged = pos_tag(cleaned_token)\n",
        "print(tagged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a95cc8a",
      "metadata": {
        "id": "2a95cc8a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65a6fe4",
      "metadata": {
        "id": "a65a6fe4"
      },
      "outputs": [],
      "source": [
        "docs = [ \"Sachin is considered to be one of the greatest cricket players\",\n",
        " \"Federer is considered one of the greatest tennis players\",\n",
        " \"Nadal is considered one of the greatest tennis players\",\n",
        " \"Virat is the captain of the Indian cricket team\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "badd7e5a",
      "metadata": {
        "id": "badd7e5a",
        "outputId": "9d900473-ca97-4b79-f1f8-7b7699ba18db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sachin': 12, 'is': 7, 'considered': 2, 'to': 16, 'be': 0, 'one': 10, 'of': 9, 'the': 15, 'greatest': 5, 'cricket': 3, 'players': 11, 'federer': 4, 'tennis': 14, 'nadal': 8, 'virat': 17, 'captain': 1, 'indian': 6, 'team': 13}\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(analyzer = \"word\", norm = None , use_idf = True , smooth_idf=True)\n",
        "Mat = vectorizer.fit(docs)\n",
        "print(Mat.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c09e91",
      "metadata": {
        "id": "36c09e91"
      },
      "outputs": [],
      "source": [
        "tfidfMat = vectorizer.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a49f3a",
      "metadata": {
        "id": "16a49f3a",
        "outputId": "916486cd-028c-48b6-c763-c23fe9c33848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 11)\t1.2231435513142097\n",
            "  (0, 3)\t1.5108256237659907\n",
            "  (0, 5)\t1.2231435513142097\n",
            "  (0, 15)\t1.0\n",
            "  (0, 9)\t1.0\n",
            "  (0, 10)\t1.2231435513142097\n",
            "  (0, 0)\t1.916290731874155\n",
            "  (0, 16)\t1.916290731874155\n",
            "  (0, 2)\t1.2231435513142097\n",
            "  (0, 7)\t1.0\n",
            "  (0, 12)\t1.916290731874155\n",
            "  (1, 14)\t1.5108256237659907\n",
            "  (1, 4)\t1.916290731874155\n",
            "  (1, 11)\t1.2231435513142097\n",
            "  (1, 5)\t1.2231435513142097\n",
            "  (1, 15)\t1.0\n",
            "  (1, 9)\t1.0\n",
            "  (1, 10)\t1.2231435513142097\n",
            "  (1, 2)\t1.2231435513142097\n",
            "  (1, 7)\t1.0\n",
            "  (2, 8)\t1.916290731874155\n",
            "  (2, 14)\t1.5108256237659907\n",
            "  (2, 11)\t1.2231435513142097\n",
            "  (2, 5)\t1.2231435513142097\n",
            "  (2, 15)\t1.0\n",
            "  (2, 9)\t1.0\n",
            "  (2, 10)\t1.2231435513142097\n",
            "  (2, 2)\t1.2231435513142097\n",
            "  (2, 7)\t1.0\n",
            "  (3, 13)\t1.916290731874155\n",
            "  (3, 6)\t1.916290731874155\n",
            "  (3, 1)\t1.916290731874155\n",
            "  (3, 17)\t1.916290731874155\n",
            "  (3, 3)\t1.5108256237659907\n",
            "  (3, 15)\t2.0\n",
            "  (3, 9)\t1.0\n",
            "  (3, 7)\t1.0\n"
          ]
        }
      ],
      "source": [
        "print(tfidfMat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c5dcc0",
      "metadata": {
        "id": "93c5dcc0",
        "outputId": "695aa209-a86c-4259-be19-fafaae158f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['be' 'captain' 'considered' 'cricket' 'federer' 'greatest' 'indian' 'is'\n",
            " 'nadal' 'of' 'one' 'players' 'sachin' 'team' 'tennis' 'the' 'to' 'virat']\n"
          ]
        }
      ],
      "source": [
        "features_names = vectorizer.get_feature_names_out()\n",
        "print(features_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514ea886",
      "metadata": {
        "id": "514ea886"
      },
      "outputs": [],
      "source": [
        "dense = tfidfMat.todense()\n",
        "denselist = dense.tolist()\n",
        "df = pd.DataFrame(denselist , columns = features_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160bf2f9",
      "metadata": {
        "id": "160bf2f9",
        "outputId": "b68e51ba-6b73-4c0b-d9b9-b6f323f01923"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>be</th>\n",
              "      <th>captain</th>\n",
              "      <th>considered</th>\n",
              "      <th>cricket</th>\n",
              "      <th>federer</th>\n",
              "      <th>greatest</th>\n",
              "      <th>indian</th>\n",
              "      <th>is</th>\n",
              "      <th>nadal</th>\n",
              "      <th>of</th>\n",
              "      <th>one</th>\n",
              "      <th>players</th>\n",
              "      <th>sachin</th>\n",
              "      <th>team</th>\n",
              "      <th>tennis</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>virat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.916291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>1.510826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>1.916291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.916291</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.916291</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.510826</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.916291</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>1.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.510826</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.916291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.510826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.916291</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.916291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.916291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         be   captain  considered   cricket   federer  greatest    indian  \\\n",
              "0  1.916291  0.000000    1.223144  1.510826  0.000000  1.223144  0.000000   \n",
              "1  0.000000  0.000000    1.223144  0.000000  1.916291  1.223144  0.000000   \n",
              "2  0.000000  0.000000    1.223144  0.000000  0.000000  1.223144  0.000000   \n",
              "3  0.000000  1.916291    0.000000  1.510826  0.000000  0.000000  1.916291   \n",
              "\n",
              "    is     nadal   of       one   players    sachin      team    tennis  the  \\\n",
              "0  1.0  0.000000  1.0  1.223144  1.223144  1.916291  0.000000  0.000000  1.0   \n",
              "1  1.0  0.000000  1.0  1.223144  1.223144  0.000000  0.000000  1.510826  1.0   \n",
              "2  1.0  1.916291  1.0  1.223144  1.223144  0.000000  0.000000  1.510826  1.0   \n",
              "3  1.0  0.000000  1.0  0.000000  0.000000  0.000000  1.916291  0.000000  2.0   \n",
              "\n",
              "         to     virat  \n",
              "0  1.916291  0.000000  \n",
              "1  0.000000  0.000000  \n",
              "2  0.000000  0.000000  \n",
              "3  0.000000  1.916291  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37520ccc",
      "metadata": {
        "id": "37520ccc",
        "outputId": "9d1120ba-ef38-4a72-cdd7-1cf493d3ae32"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16340\\2669239957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
          ]
        }
      ],
      "source": [
        "features_names = sorted(vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02ac24f",
      "metadata": {
        "id": "a02ac24f",
        "outputId": "20e6ba80-27d4-4c33-f65b-65d43ab94b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             be   captain  considered   cricket   federer  greatest    indian  \\\n",
            "Doc 1  1.916291  0.000000    1.223144  1.510826  0.000000  1.223144  0.000000   \n",
            "Doc 2  0.000000  0.000000    1.223144  0.000000  1.916291  1.223144  0.000000   \n",
            "Doc 3  0.000000  0.000000    1.223144  0.000000  0.000000  1.223144  0.000000   \n",
            "Doc 4  0.000000  1.916291    0.000000  1.510826  0.000000  0.000000  1.916291   \n",
            "\n",
            "        is     nadal   of       one   players    sachin      team    tennis  \\\n",
            "Doc 1  1.0  0.000000  1.0  1.223144  1.223144  1.916291  0.000000  0.000000   \n",
            "Doc 2  1.0  0.000000  1.0  1.223144  1.223144  0.000000  0.000000  1.510826   \n",
            "Doc 3  1.0  1.916291  1.0  1.223144  1.223144  0.000000  0.000000  1.510826   \n",
            "Doc 4  1.0  0.000000  1.0  0.000000  0.000000  0.000000  1.916291  0.000000   \n",
            "\n",
            "       the        to     virat  \n",
            "Doc 1  1.0  1.916291  0.000000  \n",
            "Doc 2  1.0  0.000000  0.000000  \n",
            "Doc 3  1.0  0.000000  0.000000  \n",
            "Doc 4  2.0  0.000000  1.916291  \n"
          ]
        }
      ],
      "source": [
        "docList = ['Doc 1','Doc 2','Doc 3','Doc 4']\n",
        "skDocsIfIdfdf = pd.DataFrame(tfidfMat.todense(),index = sorted(docList), columns=features_names)\n",
        "print(skDocsIfIdfdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ed9a3a",
      "metadata": {
        "id": "a1ed9a3a"
      },
      "outputs": [],
      "source": [
        "csim = cosine_similarity(tfidfMat,tfidfMat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9555f330",
      "metadata": {
        "id": "9555f330"
      },
      "outputs": [],
      "source": [
        "csimDf = pd.DataFrame(csim,index=sorted(docList),columns=sorted(docList))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ea2806",
      "metadata": {
        "id": "e8ea2806",
        "outputId": "5c751b8d-abee-449a-d5fc-fe851fd57224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Doc 1     Doc 2     Doc 3     Doc 4\n",
            "Doc 1  1.000000  0.492416  0.492416  0.277687\n",
            "Doc 2  0.492416  1.000000  0.754190  0.215926\n",
            "Doc 3  0.492416  0.754190  1.000000  0.215926\n",
            "Doc 4  0.277687  0.215926  0.215926  1.000000\n"
          ]
        }
      ],
      "source": [
        "print(csimDf)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}